{
  "input": null,
  "output": null,
  "pipeline": null,
  "components": [
    {
      "componentInstance": "lexicalEntriesExportFromSQL",
      "class": "SQLStreamTransformer",
      "driver": null,
      "connectUrl": "jdbc:mysql://localhost:3306/lexisdb",
      "user": "root",
      "password": "<$param0>",
      "query": "scripts/exportLexicalEntries.sql",
      "outFormat": "TSV",
      //the following will be ignored, since outFormat is defined.
      "escapeChar": null,
      "delimiterCSV": "\t",
      "quoteChar": null,
      "emptyChar": "_"
    },
    {
      "componentInstance" : "duplicateSqlResults",
      "class" : "IOStreamDuplicator"
    },
    {
      "componentInstance": "lexicalEntriesMappingTarql",
      "class": "TarqlStreamTransformer",
      "query" : "scripts/lexicalEntriesConstructMapping.sparql",
      "delimiterCSV": "\t",
      "tabs": "no",
      "quoteChar": null,
      "escapeChar": null,
      "encoding": "UTF-8",
      "headerRow": false,
      "baseIRI": null,
      "write-base": null,
      "dedup": "0"
    },
    {
      "componentInstance": "duplicateLexicalEntriesTarqlResults",
      "class": "IOStreamDuplicator"
    },
    {
      "componentInstance": "loadLexicalEntriesToGraph",
      "class": "RDFStreamLoader",
      "lang": "Turtle",
      "globalPrefixes": true,
      //split after every linebreak
      "delimiter": "",
      "split": true
    },
    {
      "componentInstance": "gramcatMappingTarql",
      "class": "TarqlStreamTransformer",
      "query": "scripts/gramcatConstructMapping.sparql",
      "delimiterCSV": ",",
      "tabs": "no",
      "quoteChar": null,
      "escapeChar": null,
      "encoding": "UTF-8",
      "headerRow": true,
      "baseIRI": null,
      "write-base": null,
      "dedup": "0"
    },
    {
      "componentInstance": "duplicateGramcatTarqlResults",
      "class": "IOStreamDuplicator"
    },
    {
      "componentInstance": "loadGramcatToGraph",
      "class": "RDFStreamLoader",
      "lang": "Turtle",
      "globalPrefixes": true,
      //never split
      "delimiter": null,
      "split": false
    },
    {
      "componentInstance": "updatePOS",
      "class": "RDFUpdater",
      "threads": "0",
      "lookahead": "0",
      "lookback": "0",
      "updates": [
        {
          "path": "scripts/gramcatUpdatePOS.sparql",
          "iter": 1
        }
      ]
    },
    {
      "componentInstance": "writeTTL",
      "class": "RDFStreamWriter",
      "lang": "Turtle",
      "delimiter": "",
      "prefixDeduplication": true
    }
  ],
  "streams": [
    // First Stream
		// Read Lexical entry tsv generated by SQL query into Duplicator
		{
			"readsFromInstance": "lexicalEntriesExportFromSQL",
			"writesToInstance": "duplicateSqlResults"
		},
    // Export SQL-tsv results from db export
    {
      "readsFromInstance": "duplicateSqlResults",
      "writesToDestination": "LexisFinalRDF/exportedSqlResults.tsv"
    },
    // SQL-tsv result to TARQL construction
    {
      "readsFromInstance": "duplicateSqlResults",
      "writesToInstance": "lexicalEntriesMappingTarql"
    },
		// Load the LexicalEntries TARQL results into duplicator
    {
      "readsFromInstance": "lexicalEntriesMappingTarql",
      "writesToInstance": "duplicateLexicalEntriesTarqlResults"
    },
    // Export LexicalEntries TARQL results as a transformed mapping file
    {
      "readsFromInstance": "duplicateLexicalEntriesTarqlResults",
      "writesToDestination": "LexisFinalRDF/exportedLexicalEntriesMapping.ttl"
    },
    // Load Lexical Entries TARQL results into segmented Graph
    {
      "readsFromInstance": "duplicateLexicalEntriesTarqlResults",
      "writesToInstance": "loadLexicalEntriesToGraph",
      "writesToInstanceGraph": "lexicalEntries"
    },
    // Load Lexical Entries to Updater
    {
      "readsFromInstance": "loadLexicalEntriesToGraph",
      "readsFromInstanceGraph": "lexicalEntries",
      "writesToInstance": "updatePOS",
      "writesToInstanceGraph": ""
    },

    // Second Stream
    // Read Gramcat Mapping file into TARQL
    {
      "readsFromSource": "data/gramcat.csv",
      "writesToInstance": "gramcatMappingTarql",
      "writesToInstanceGraph": ""
    },
    // Load the Gramcat TARQL results into duplicator
    {
      "readsFromInstance": "gramcatMappingTarql",
      "readsFromInstanceGraph": "",
      "writesToInstance": "duplicateGramcatTarqlResults",
      "writesToInstanceGraph": ""
    },
    // Export Gramcat TARQL results as a transformed mapping file
    {
      "readsFromInstance": "duplicateGramcatTarqlResults",
      "readsFromInstanceGraph": "",
      "writesToDestination": "LexisFinalRDF/exportedGramcatMapping.ttl"
    },
    // Load Gramcat TARQL results into segmented Graph
    {
      "readsFromInstance": "duplicateGramcatTarqlResults",
      "writesToInstance": "loadGramcatToGraph",
      "writesToInstanceGraph": "gramcatMapping"
    },
    // Side-Load segmented Graph to Updater as named Graph <http://mapping>
    {
      "readsFromInstance": "loadGramcatToGraph",
      "readsFromInstanceGraph": "gramcatMapping",
      "writesToInstance": "updatePOS",
      "writesToInstanceGraph": "http://mapping"
    },

    // Third Stream -  from here the first and second streams are merged
    // Pipe results of updater into RDF Writer
    {
      "readsFromInstance": "updatePOS",
      "readsFromInstanceGraph": "",
      "writesToInstance": "writeTTL",
      "writesToInstanceGraph": ""
    },
    // Export Output file
    {
      "readsFromInstance": "writeTTL",
      "readsFromInstanceGraph": "",
      "writesToDestination": "LexisFinalRDF/lexis.ttl"
    }
  ]
}
